{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b4956d",
   "metadata": {},
   "source": [
    "# Driver Drowsiness Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ef1b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Version opencv: 4.5.5\n",
      "Version tensorflow: 2.9.1\n",
      "Version keras: 2.9.0\n",
      "Version pygame: 2.1.2\n",
      "Version numpy: 1.20.3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pygame\n",
    "from pygame import mixer\n",
    "import matplotlib.pyplot as plt\n",
    "import pygame.camera\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(f\"Version opencv: {cv2.__version__}\")\n",
    "print(f\"Version tensorflow: {tf.__version__}\")\n",
    "print(f\"Version keras: {keras.__version__}\")\n",
    "print(f\"Version pygame: {pygame.__version__}\")\n",
    "print(f\"Version numpy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a236c",
   "metadata": {},
   "source": [
    "### Take picture using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed0b656",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "result, image = cam.read()\n",
    "\n",
    "if result:\n",
    "    # show the image\n",
    "    plt.imshow(\"Foto\", image)\n",
    "else:\n",
    "    print(\"Move to this part is input image has some error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb53d58",
   "metadata": {},
   "source": [
    "### Create sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438dbd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "sound = mixer.Sound('Drowsiness detection/alarm.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3965a642",
   "metadata": {},
   "source": [
    "### Take picture using pygame and select ROI manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca525911",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_pictures = 1\n",
    "\n",
    "def take_picture_roi(n):\n",
    "    if n == 0:\n",
    "        return\n",
    "    else:\n",
    "        # initializing the camera\n",
    "        pygame.camera.init()\n",
    "        # make the list of all available cameras\n",
    "        camlist = pygame.camera.list_cameras()\n",
    "        # if camera is detected or not\n",
    "        if camlist:\n",
    "            # initializing the cam variable with default camera\n",
    "            cam = pygame.camera.Camera(camlist[0], (640, 480))\n",
    "            # opening the camera\n",
    "            cam.start()\n",
    "            # capturing the single image\n",
    "            image = cam.get_image()\n",
    "            # saving the image\n",
    "            pygame.image.save(image, \"filename.jpg\")\n",
    "        # if camera is not detected the moving to else part\n",
    "        else:\n",
    "            print(\"No camera on current device\")\n",
    "            \n",
    "        cam.stop()\n",
    "         #image_path\n",
    "        img_path=\"filename.jpg\"\n",
    "        #read image\n",
    "        img_raw = cv2.imread(img_path)\n",
    "        #select ROI function\n",
    "        roi = cv2.selectROI(img_raw)\n",
    "        #print rectangle points of selected roi\n",
    "        print(roi)\n",
    "        #Crop selected roi from raw image\n",
    "        roi_cropped = img_raw[int(roi[1]):int(roi[1]+roi[3]), int(roi[0]):int(roi[0]+roi[2])]\n",
    "        #show cropped image\n",
    "        #cv2.imshow(\"ROI\", roi_cropped)\n",
    "        cv2.imwrite(\"crop.jpeg\",roi_cropped)\n",
    "        #hold window\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyWindow()\n",
    "        n = n - 1\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    take_picture_roi(number_of_pictures)\n",
    "    print(\"All pictures have been taken.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f8d152",
   "metadata": {},
   "source": [
    "### Take picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98da4275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pictures have been taken.\n"
     ]
    }
   ],
   "source": [
    "number_of_pics = 1\n",
    "\n",
    "def take_picture(n):\n",
    "    if n == 0:\n",
    "        return\n",
    "    else:\n",
    "        # initializing the camera\n",
    "        pygame.camera.init()\n",
    "        # make the list of all available cameras\n",
    "        camlist = pygame.camera.list_cameras()\n",
    "        # if camera is detected or not\n",
    "        if camlist:\n",
    "            # initializing the cam variable with default camera\n",
    "            cam = pygame.camera.Camera(camlist[0], (640, 480))\n",
    "            # opening the camera\n",
    "            cam.start()\n",
    "            # capturing the single image\n",
    "            image = cam.get_image()\n",
    "            # saving the image\n",
    "            pygame.image.save(image, \"filename.jpg\")\n",
    "        # if camera is not detected the moving to else part\n",
    "        else:\n",
    "            print(\"No camera on current device\")\n",
    "            \n",
    "        cam.stop()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    take_picture(number_of_pics)\n",
    "    print(\"All pictures have been taken.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a95df",
   "metadata": {},
   "source": [
    "### Apply model on live taken pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88caffd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(720, 1280)\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "rpred: [[0.97756165 0.0224383 ]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "lpred: [[0.97756165 0.0224383 ]]\n",
      "lprednew: [1, 0]\n",
      "2e element lprednew: 0\n"
     ]
    }
   ],
   "source": [
    "img_path=\"filename.jpg\"\n",
    "#read image\n",
    "image_color = cv2.imread(img_path)\n",
    "height,width = image_color.shape[:2]\n",
    "gray = cv2.cvtColor(image_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(type(gray))\n",
    "print(gray.shape)\n",
    "\n",
    "face=cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_frontalface_default.xml\")\n",
    "#face = cv2.CascadeClassifier(\"/Drowsiness detection/haar cascade files/haarcascade_frontalface_alt.xml\")\n",
    "faces = face.detectMultiScale(gray)\n",
    "\n",
    "leye = cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_lefteye_2splits.xml\")\n",
    "#face = cv2.CascadeClassifier(\"/Drowsiness detection/haar cascade files/haarcascade_frontalface_alt.xml\")\n",
    "left_eyes = face.detectMultiScale(gray)\n",
    "\n",
    "reye = cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_righteye_2splits.xml\")\n",
    "#face = cv2.CascadeClassifier(\"/Drowsiness detection/haar cascade files/haarcascade_frontalface_alt.xml\")\n",
    "right_eyes = face.detectMultiScale(gray)\n",
    "\n",
    "lbl=['Close','Open']\n",
    "model = load_model('Drowsiness detection/models/cnncat2.h5')\n",
    "path = os.getcwd()\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "count=0\n",
    "score=0\n",
    "thicc=2\n",
    "rpred=[99]\n",
    "lpred=[99]\n",
    "\n",
    "cv2.rectangle(image_color, (0,height-50) , (200,height) , (0,0,0) , thickness=cv2.FILLED )\n",
    "\n",
    "for (x,y,w,h) in faces: \n",
    "        fot01 = cv2.rectangle(image_color, (x,y), (x+w, y+h), (100,100,100), 1 )\n",
    "        \n",
    "for (x,y,w,h) in right_eyes:\n",
    "        r_eye=image_color[y:y+h,x:x+w]\n",
    "        count=count+1\n",
    "        r_eye = cv2.cvtColor(r_eye,cv2.COLOR_BGR2GRAY)\n",
    "        r_eye = cv2.resize(r_eye,(24,24))\n",
    "        r_eye= r_eye/255\n",
    "        r_eye= r_eye.reshape(24,24,-1)\n",
    "        r_eye = np.expand_dims(r_eye,axis=0)\n",
    "        rpred = model.predict(r_eye)\n",
    "        print(f\"rpred: {rpred}\")\n",
    "        rprednew = []\n",
    "        for i in rpred:\n",
    "            for j in i:\n",
    "                if j > 0.51:\n",
    "                    j = 1\n",
    "                    rprednew.append(j)\n",
    "                else:\n",
    "                    j = 0\n",
    "                    rprednew.append(j)\n",
    "        if(rprednew[0]==0):\n",
    "            lbl='Open'\n",
    "        if(rprednew[0]==1):\n",
    "            lbl='Closed'\n",
    "        break\n",
    "for (x,y,w,h) in left_eyes:\n",
    "    l_eye=image_color[y:y+h,x:x+w]\n",
    "    count=count+1\n",
    "    l_eye = cv2.cvtColor(l_eye,cv2.COLOR_BGR2GRAY)\n",
    "    l_eye = cv2.resize(l_eye,(24,24))\n",
    "    l_eye= l_eye/255\n",
    "    l_eye=l_eye.reshape(24,24,-1)\n",
    "    l_eye = np.expand_dims(l_eye,axis=0)\n",
    "    lpred = model.predict(l_eye)\n",
    "    print(f\"lpred: {lpred}\")\n",
    "    lprednew = []\n",
    "    for i in lpred:\n",
    "        for j in i:\n",
    "            if j > 0.51:\n",
    "                j = 1\n",
    "                lprednew.append(j)\n",
    "            else:\n",
    "                j = 0\n",
    "                lprednew.append(j)\n",
    "    print(f\"lprednew: {lprednew}\")\n",
    "    if (lprednew[0]==0):\n",
    "        lbl='Open'\n",
    "    if (lprednew[0]==1):\n",
    "        print(f\"2e element lprednew: {lprednew[1]}\")\n",
    "        lbl='Closed'\n",
    "    break\n",
    "if(rprednew[0]==1 and lprednew[0]==1):\n",
    "    score=score+1\n",
    "    cv2.putText(image_color,\"Closed:\"+str(score),(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "# if(rpred[0]==1 or lpred[0]==1):\n",
    "else:\n",
    "    score=score-1\n",
    "    cv2.putText(image_color,\"Open\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "if(score<0):\n",
    "    score=0\n",
    "    cv2.putText(image_color,'Score:'+str(score),(100,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "if(score>15):\n",
    "    #person is feeling sleepy so we beep the alarm\n",
    "    cv2.imwrite(os.path.join(path,'image.jpg'),image_color)\n",
    "    try:\n",
    "        sound.play()\n",
    "    except: # isplaying = False\n",
    "        pass\n",
    "    if(thicc<16):\n",
    "        thicc= thicc+2\n",
    "    else:\n",
    "        thicc=thicc-2\n",
    "        if(thicc<2):\n",
    "            thicc=2\n",
    "cv2.rectangle(image_color,(0,0),(width,height),(0,0,255),thicc)\n",
    "cv2.imshow('frame',image_color)\n",
    "if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    cv2.destroyAllWindows()\n",
    "    #break\n",
    "#cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1be016",
   "metadata": {},
   "source": [
    "### Apply model on dataset of faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956375bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path=\"dataset_new/test/testimages\"\n",
    "\n",
    "def model_on_dataset(images_path):\n",
    "    for subdir, dirs, files in os.walk(images_path):\n",
    "        for image in files:\n",
    "            path_file = os.path.join(subdir, image)\n",
    "            print(f\"image:{image}\")\n",
    "            image_color = cv2.imread(path_file)\n",
    "            height,width = image_color.shape[:2]\n",
    "            gray = cv2.cvtColor(image_color, cv2.COLOR_BGR2GRAY)\n",
    "            print(type(gray))\n",
    "            print(gray.shape)\n",
    "            face=cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_frontalface_default.xml\")\n",
    "            #face = cv2.CascadeClassifier(\"/Drowsiness detection/haar cascade files/haarcascade_frontalface_alt.xml\")\n",
    "            faces = face.detectMultiScale(gray)\n",
    "            leye = cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_lefteye_2splits.xml\")\n",
    "            #face = cv2.CascadeClassifier(\"/Drowsiness detection/haar cascade files/haarcascade_frontalface_alt.xml\")\n",
    "            left_eyes = face.detectMultiScale(gray)\n",
    "            reye = cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_righteye_2splits.xml\")\n",
    "            #face = cv2.CascadeClassifier(\"/Drowsiness detection/haar cascade files/haarcascade_frontalface_alt.xml\")\n",
    "            right_eyes = face.detectMultiScale(gray)\n",
    "            lbl=['Close','Open']\n",
    "            model = load_model('Drowsiness detection/models/cnncat2.h5')\n",
    "            path = os.getcwd()\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "            count=0\n",
    "            score=0\n",
    "            thicc=2\n",
    "            rpred=[99]\n",
    "            lpred=[99]\n",
    "            cv2.rectangle(image_color, (0,height-50) , (200,height) , (0,0,0) , thickness=cv2.FILLED )\n",
    "            for (x,y,w,h) in faces: \n",
    "                    fot01 = cv2.rectangle(image_color, (x,y), (x+w, y+h), (100,100,100), 1 )\n",
    "            for (x,y,w,h) in right_eyes:\n",
    "                    r_eye=image_color[y:y+h,x:x+w]\n",
    "                    count=count+1\n",
    "                    r_eye = cv2.cvtColor(r_eye,cv2.COLOR_BGR2GRAY)\n",
    "                    r_eye = cv2.resize(r_eye,(24,24))\n",
    "                    r_eye= r_eye/255\n",
    "                    r_eye= r_eye.reshape(24,24,-1)\n",
    "                    r_eye = np.expand_dims(r_eye,axis=0)\n",
    "                    rpred = model.predict(r_eye)\n",
    "                    print(f\"rpred: {rpred}\")\n",
    "                    rprednew = []\n",
    "                    for i in rpred:\n",
    "                        for j in i:\n",
    "                            if j > 0.51:\n",
    "                                j = 1\n",
    "                                rprednew.append(j)\n",
    "                            else:\n",
    "                                j = 0\n",
    "                                rprednew.append(j)\n",
    "                    if(rprednew[0]==0):\n",
    "                        lbl='Open'\n",
    "                    if(rprednew[0]==1):\n",
    "                        lbl='Closed'\n",
    "                    break\n",
    "            for (x,y,w,h) in left_eyes:\n",
    "                l_eye=image_color[y:y+h,x:x+w]\n",
    "                count=count+1\n",
    "                l_eye = cv2.cvtColor(l_eye,cv2.COLOR_BGR2GRAY)\n",
    "                l_eye = cv2.resize(l_eye,(24,24))\n",
    "                l_eye= l_eye/255\n",
    "                l_eye=l_eye.reshape(24,24,-1)\n",
    "                l_eye = np.expand_dims(l_eye,axis=0)\n",
    "                lpred = model.predict(l_eye)\n",
    "                print(f\"lpred: {lpred}\")\n",
    "                lprednew = []\n",
    "                for i in lpred:\n",
    "                    for j in i:\n",
    "                        if j > 0.51:\n",
    "                            j = 1\n",
    "                            lprednew.append(j)\n",
    "                        else:\n",
    "                            j = 0\n",
    "                            lprednew.append(j)\n",
    "                print(f\"lprednew: {lprednew}\")\n",
    "                if (lprednew[0]==0):\n",
    "                    lbl='Open'\n",
    "                if (lprednew[0]==1):\n",
    "                    print(f\"2e element lprednew: {lprednew[1]}\")\n",
    "                    lbl='Closed'\n",
    "                break\n",
    "            if(rprednew[0]==1 and lprednew[0]==1):\n",
    "                score=score+1\n",
    "                cv2.putText(image_color,\"Closed:\"+str(score),(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "            # if(rpred[0]==1 or lpred[0]==1):\n",
    "            else:\n",
    "                score=score-1\n",
    "                cv2.putText(image_color,\"Open\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "            if(score<0):\n",
    "                score=0\n",
    "                cv2.putText(image_color,'Score:'+str(score),(100,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "            if(score>15):\n",
    "                #person is feeling sleepy so we beep the alarm\n",
    "                cv2.imwrite(os.path.join(path,'image.jpg'),image_color)\n",
    "                try:\n",
    "                    sound.play()\n",
    "                except: # isplaying = False\n",
    "                    pass\n",
    "                if(thicc<16):\n",
    "                    thicc= thicc+2\n",
    "                else:\n",
    "                    thicc=thicc-2\n",
    "                    if(thicc<2):\n",
    "                        thicc=2\n",
    "            cv2.rectangle(image_color,(0,0),(width,height),(0,0,255),thicc)\n",
    "            cv2.imshow('frame',image_color)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f32f7013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image:n9Eaf2lOZ1kFLYH-Pl4G.jpg\n",
      "<class 'numpy.ndarray'>\n",
      "(450, 319)\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "rpred: [[1.0000000e+00 2.0389291e-16]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "lpred: [[1.0000000e+00 2.0389291e-16]]\n",
      "lprednew: [1, 0]\n",
      "2e element lprednew: 0\n",
      "image:woman-closed-eyes-portrait-young-beautiful-naked-shoulders-posing-white-background-103120013.jpg\n",
      "<class 'numpy.ndarray'>\n",
      "(533, 800)\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "rpred: [[1.0000000e+00 1.9246008e-11]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "lpred: [[1.0000000e+00 1.9246008e-11]]\n",
      "lprednew: [1, 0]\n",
      "2e element lprednew: 0\n",
      "image:images.jpeg\n",
      "<class 'numpy.ndarray'>\n",
      "(253, 199)\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "rpred: [[1.0000000e+00 2.4032846e-12]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "lpred: [[1.0000000e+00 2.4032846e-12]]\n",
      "lprednew: [1, 0]\n",
      "2e element lprednew: 0\n",
      "image:1234.jpg\n",
      "<class 'numpy.ndarray'>\n",
      "(1316, 858)\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "rpred: [[1.0000000e+00 3.6166645e-09]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "lpred: [[1.0000000e+00 3.6166645e-09]]\n",
      "lprednew: [1, 0]\n",
      "2e element lprednew: 0\n",
      "image:calm-relaxed-healthy-sleeping-beautiful-260nw-1781515730.jpg\n",
      "<class 'numpy.ndarray'>\n",
      "(280, 390)\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "rpred: [[9.9999988e-01 9.8426185e-08]]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "lpred: [[9.9999988e-01 9.8426185e-08]]\n",
      "lprednew: [1, 0]\n",
      "2e element lprednew: 0\n",
      "image:istockphoto-1019967998-612x612.jpg\n",
      "<class 'numpy.ndarray'>\n",
      "(402, 612)\n",
      "image:shape-eth-800x600px.jpg.webp\n",
      "<class 'numpy.ndarray'>\n",
      "(600, 800)\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "rpred: [[0.13085549 0.8691445 ]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "lpred: [[0.13085549 0.8691445 ]]\n",
      "lprednew: [0, 1]\n",
      "image:134605100-beauty-portrait-of-beautiful-african-american-girl-with-closed-eyes-natural-makeup-and-perfect-skin.jpg\n",
      "<class 'numpy.ndarray'>\n",
      "(300, 450)\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "rpred: [[9.999993e-01 6.949626e-07]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "lpred: [[9.999993e-01 6.949626e-07]]\n",
      "lprednew: [1, 0]\n",
      "2e element lprednew: 0\n",
      "image:istockphoto-183854309-170667a.jpg\n",
      "<class 'numpy.ndarray'>\n",
      "(370, 463)\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "rpred: [[0.99088895 0.0091111 ]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "lpred: [[0.99088895 0.0091111 ]]\n",
      "lprednew: [1, 0]\n",
      "2e element lprednew: 0\n",
      "image:promo-f479f33fd9304b3997cc0f7c97c1a245-1aebc5f0ea88447e840db1f8fd67f802.jpg\n",
      "<class 'numpy.ndarray'>\n",
      "(800, 1000)\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "rpred: [[9.9999976e-01 2.6479844e-07]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "lpred: [[9.9999976e-01 2.6479844e-07]]\n",
      "lprednew: [1, 0]\n",
      "2e element lprednew: 0\n"
     ]
    }
   ],
   "source": [
    "model_on_dataset(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586bba95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
